{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "numx = 0\n",
    "\n",
    "def make_data():\n",
    "    \n",
    "\timageData=[]\n",
    "\tlabels=[]\n",
    "\tdata=[]\n",
    "\tfeatures=28*28*3\n",
    "\tnoImage=96000\n",
    "\tnClass=96\n",
    "\tpath=os.getcwd()\n",
    "\tfolderpath=os.path.join(path,\"classes\")\n",
    "\tvidpath=os.path.join(path,\"vimage\")\n",
    "\n",
    "\tlabel=-1\n",
    "\tfor length in range(2):\n",
    "\t\tfor width in range(2):\n",
    "\t\t\tfor angle in range(12):\n",
    "\t\t\t\tfor color in range(2):\n",
    "\n",
    "\t\t\t\t\tstring=str(length)+\"_\"+str(width)+\"_\"+str(angle)+\"_\"+str(color)\n",
    "\t\t\t\t\tfpath=folderpath+\"/\"+string\n",
    "\n",
    "\t\t\t\t\tipath=fpath+\"/\"+str(length)+\"_\"+str(width)+\"_\"+str(angle)+\"_\"+str(color)\n",
    "\t\t\t\t\tlabel=label+1\n",
    "\n",
    "\t\t\t\t\tfor image in range(1000):\n",
    "\t\t\t\t\t\tiName=ipath+\"_\"+str(image)+\".jpeg\"\n",
    "\t\t\t\t\t\timg_data=cv2.imread(iName)\n",
    "\t\t\t\t\t\tdata.append(img_data.flatten().reshape(features))\n",
    "\t\t\t\t\t\tlabels.append(label)\n",
    "\timageData=np.array(data,float).reshape(noImage,features)\n",
    "\tlabels=np.array(labels,float).reshape(noImage,1)\n",
    "\timageData=imageData/255.0\n",
    "\tdata=np.concatenate((imageData,labels),axis=1)\n",
    "\tnp.random.shuffle(data)\n",
    "\tdata=data.reshape(noImage,features+1)\n",
    "\n",
    "\n",
    "\tipt=data[:,:-1]\n",
    "\topt=np.array(data[:,-1],int).reshape(noImage,1)\n",
    "\tb=np.zeros((noImage,nClass),int)\n",
    "\tfor i in range(noImage):\n",
    "\t\tb[i,opt[i]]=1\n",
    "\n",
    "\treturn ipt,b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 2352) (96000, 96)\n"
     ]
    }
   ],
   "source": [
    "x,y=make_data()\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = x\n",
    "ny = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nx\n",
    "y = ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyList = []\n",
    "epochList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 2352)\n",
      "Testing Accuracy: 0.9389236\n",
      "Testing Accuracy: 0.9389236\n",
      "Testing Accuracy: 0.9389236\n",
      "Testing Accuracy: 0.9389236\n",
      "Testing Accuracy: 0.9389236\n",
      "Testing Accuracy: 0.9389236\n",
      "Testing Accuracy: 0.9389236\n",
      "Testing Accuracy: 0.9389236\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(x.shape)\n",
    "splitSize = int(x.shape[0]*0.7)\n",
    "x, testData = x[:splitSize,:], x[splitSize:,:]\n",
    "y, testY = y[:splitSize,:], y[splitSize:,:]\n",
    "\n",
    "batchPtr = 0\n",
    "# splitting the data into train, val,test\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "def batchForm():\n",
    "    # form the batch of given batch size\n",
    "    global batchPtr\n",
    "    batchX = x[batchPtr:batchPtr+batchSize,:]\n",
    "    batchY = y[batchPtr:batchPtr+batchSize,:]\n",
    "    batchPtr += batchSize\n",
    "#     print(batchX)\n",
    "#     print(batchY)\n",
    "    return batchX,batchY\n",
    "\n",
    "noInputUnit = 784*3\n",
    "noHiddenUnit = 10\n",
    "noOutputUnit = 96\n",
    "batchSize = 200\n",
    "\n",
    "# placeholder to feed values during \n",
    "x1 = tf.placeholder(tf.float32, [None, noInputUnit])\n",
    "y1 = tf.placeholder(tf.float32, [None, noOutputUnit])\n",
    "\n",
    "# set remaining parameters\n",
    "epochs = 100\n",
    "learningRate = 0.01\n",
    "\n",
    "hiddenWeight = tf.Variable(tf.random_normal([noInputUnit, noHiddenUnit], seed=seed))\n",
    "outputWeight = tf.Variable(tf.random_normal([noHiddenUnit, noOutputUnit], seed=seed))\n",
    "\n",
    "hiddenBias = tf.Variable(tf.random_normal([noHiddenUnit], seed=seed))\n",
    "outputBias = tf.Variable(tf.random_normal([noOutputUnit], seed=seed))\n",
    "\n",
    "hiddenLayer = tf.add(tf.matmul(x1, hiddenWeight), hiddenBias)\n",
    "hiddenLayer = tf.nn.relu(hiddenLayer)\n",
    "\n",
    "outputLyer = tf.matmul(hiddenLayer, outputWeight) + outputBias\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=outputLyer, labels=y1))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "for xx in range(1, 55):\n",
    "    with tf.Session() as sess:\n",
    "        # create initialized variables\n",
    "        sess.run(init)        \n",
    "        for epoch in range(epochs):\n",
    "            avgCost = 0\n",
    "            total_batch = xx\n",
    "    #         print(totalBatch)\n",
    "    #         print(x.shape[0])\n",
    "            batchPtr = 0\n",
    "            for i in range(totalBatch):\n",
    "                batchX, batchY = batchForm()\n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x1: batchX, y1: batchY})\n",
    "                avgCost += c / totalBatch \n",
    "                if xx == 53:\n",
    "                    epochList.append(avg_cost)\n",
    "\n",
    "#             print(\"Epoch:\", (epoch+1), \"cost =\", \"{:.5f}\".format(avgCost))\n",
    "\n",
    "        pred_temp = tf.equal(tf.argmax(outputLyer, 1), tf.argmax(y1, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "        accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "        ac = accuracy.eval({x1: val_x.reshape(-1, 784*3), y1: val_y})\n",
    "        print(\"Testing Accuracy:\", ac)\n",
    "        accuracyList.append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(values, nx, title, xx, yy):\n",
    "    plt.figure()\n",
    "    name = nx + \"_curve.jpg\"\n",
    "    name = str(hidden_num_units)+\"_\"+str(epochs) + name\n",
    "    name = \"./graphs/my_\" + name\n",
    "    xVal = np.arange(len(values)) * 200\n",
    "#     print(xVal)\n",
    "#     xVal.append(32)\n",
    "#     print(xVal)\n",
    "    plt.plot(xVal, values, marker='o',markersize='4', linestyle='--')\n",
    "    plt.ylabel(yy)\n",
    "    plt.xlabel(xx)\n",
    "    plt.title(title)\n",
    "#     plt.show()\n",
    "    plt.savefig(name)\n",
    "    \n",
    "plot(np.array(accuracyList), \"\", \"Learning Curve\", \"Train Data Size\", \"Accuracy\")\n",
    "plot(np.array(epochList), \"epoch\", \"Epoch vs Loss\", \"Epochs\", \"Loss Function\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
